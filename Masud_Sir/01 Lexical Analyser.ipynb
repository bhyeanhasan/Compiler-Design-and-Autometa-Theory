{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Lexical Analysis is the first phase of the compiler also known as a scanner. It converts the High level input program into a sequence of Tokens."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b036e9a066f9f8"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Defined Grammar \n",
    "\n",
    "keywords = {\"auto\", \"break\", \"case\", \"char\", \"const\", \"continue\", \"default\", \"do\",\n",
    "            \"double\", \"else\", \"enum\", \"extern\", \"float\", \"for\", \"goto\",\n",
    "            \"if\", \"int\", \"long\", \"register\", \"return\", \"short\", \"signed\",\n",
    "            \"sizeof\", \"static\", \"struct\", \"switch\", \"typedef\", \"union\",\n",
    "            \"unsigned\", \"void\", \"volatile\", \"while\", \"printf\", \"scanf\", \"%d\", \"include\", \"stdio.h\", \"main\"}\n",
    "\n",
    "operators = {\"+\", \"-\", \"*\", \"/\", \"<\", \">\", \"=\", \"<=\", \">=\", \"==\", \"!=\", \"++\", \"--\", \"%\"}\n",
    "\n",
    "delimiters = ['(', ')', '{', '}', '[', ']', '\"', \"'\", ';', '#', ',']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T15:44:13.931323500Z",
     "start_time": "2023-11-05T15:44:13.916476500Z"
    }
   },
   "id": "9a4d029e40b90dc"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Defined Functions\n",
    "\n",
    "def detect_keywords(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in keywords:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_operators(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in operators:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_delimiters(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in delimiters:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_num(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            a = int(word)\n",
    "            arr.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_identifiers(text):\n",
    "    k = detect_keywords(text)\n",
    "    o = detect_operators(text)\n",
    "    d = detect_delimiters(text)\n",
    "    n = detect_num(text)\n",
    "    not_ident = k + o + d + n\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word not in not_ident:\n",
    "            arr.append(word)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def tokenizer(txt):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "\n",
    "    while i < (len(txt)):\n",
    "\n",
    "        # if txt[i] == '\"':\n",
    "        #     string = '\"'\n",
    "        #     i = i + 1\n",
    "        #     while txt[i] != '\"':\n",
    "        #         string += txt[i]\n",
    "        #         i += 1\n",
    "        #     string += '\"'\n",
    "        #     tokens.append(string)\n",
    "\n",
    "        if txt[i] in delimiters:\n",
    "            string = txt[i]\n",
    "            i = i + 1\n",
    "            while txt[i] not in delimiters:\n",
    "                string += txt[i]\n",
    "                i += 1\n",
    "            string += txt[i]\n",
    "            tokens.append(string)\n",
    "\n",
    "        i = i + 1\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:23:40.874947600Z",
     "start_time": "2023-11-05T16:23:40.869445500Z"
    }
   },
   "id": "f54119d0e356efea"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ami first line\" print(\"amin print\") \"ses line\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'delimiters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m x \u001B[38;5;241m=\u001B[39m txt\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(x)\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m delimiters:\n\u001B[0;32m      7\u001B[0m     lst \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msplit(i)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m lst:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'delimiters' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "txt = ['\"ami first line\" print(\"amin print\") \"ses line\"']\n",
    "\n",
    "for xx in range(5):\n",
    "    x = txt.pop()\n",
    "    print(x)\n",
    "    for i in delimiters:\n",
    "        lst = x.split(i)\n",
    "        for j in lst:\n",
    "            txt.append(j)\n",
    "    print(txt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T15:20:10.120133400Z",
     "start_time": "2024-01-17T15:20:09.314798200Z"
    }
   },
   "id": "7a4994a486789400"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:  ['%d', 'int', 'return']\n",
      "Operators:  ['=']\n",
      "Delimiters:  ['}', '{']\n",
      "Identifiers:  ['#include', '<stdio.h>', '//', 'This', 'is', 'a', 'header', 'file', 'main()', 'a;', 'a', '10;', 'printf(\"The', 'value', 'of', 'a', 'is', '\",a);', '0;']\n",
      "Numbers:  []\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt') as t:\n",
    "    text = t.read().split()\n",
    "\n",
    "print(\"Keywords: \", detect_keywords(text))\n",
    "print(\"Operators: \", detect_operators(text))\n",
    "print(\"Delimiters: \", detect_delimiters(text))\n",
    "print(\"Identifiers: \", detect_identifiers(text))\n",
    "print(\"Numbers: \", detect_num(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T15:11:44.992930900Z",
     "start_time": "2023-11-05T15:11:44.966259400Z"
    }
   },
   "id": "7b143cdfb570ff59"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATATYPE', 'int'], ['IDENTIFIER', 'result'], ['OPERATOR', '='], ['INTEGER', '100'], ['END_STATEMENT', ';']]\n"
     ]
    }
   ],
   "source": [
    "import re  # for performing regex expressions\n",
    "\n",
    "tokens = []  # for string tokens\n",
    "source_code = 'int result = 100;'.split()  # turning source code into list of words\n",
    "\n",
    "# Loop through each source code word\n",
    "for word in source_code:\n",
    "\n",
    "    # This will check if a token has datatype decleration\n",
    "    if word in ['str', 'int', 'bool']:\n",
    "        tokens.append(['DATATYPE', word])\n",
    "\n",
    "    # This will look for an identifier which would be just a word\n",
    "    elif re.match(\"[a-z]\", word) or re.match(\"[A-Z]\", word):\n",
    "        tokens.append(['IDENTIFIER', word])\n",
    "\n",
    "    # This will look for an operator\n",
    "    elif word in '*-/+%=':\n",
    "        tokens.append(['OPERATOR', word])\n",
    "\n",
    "    # This will look for integer items and cast them as a number\n",
    "    elif re.match(\".[0-9]\", word):\n",
    "        if word[len(word) - 1] == ';':\n",
    "            tokens.append([\"INTEGER\", word[:-1]])\n",
    "            tokens.append(['END_STATEMENT', ';'])\n",
    "        else:\n",
    "            tokens.append([\"INTEGER\", word])\n",
    "\n",
    "print(tokens)  # Outputs the token array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T15:12:10.486598600Z",
     "start_time": "2023-11-05T15:12:10.462073800Z"
    }
   },
   "id": "2523cab0abad54d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ae1f2bad49eba4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
