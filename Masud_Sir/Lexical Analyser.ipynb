{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "keywords = {\"auto\", \"break\", \"case\", \"char\", \"const\", \"continue\", \"default\", \"do\",\n",
    "            \"double\", \"else\", \"enum\", \"extern\", \"float\", \"for\", \"goto\",\n",
    "            \"if\", \"int\", \"long\", \"register\", \"return\", \"short\", \"signed\",\n",
    "            \"sizeof\", \"static\", \"struct\", \"switch\", \"typedef\", \"union\",\n",
    "            \"unsigned\", \"void\", \"volatile\", \"while\", \"printf\", \"scanf\", \"%d\", \"include\", \"stdio.h\", \"main\"}\n",
    "\n",
    "operators = {\"+\", \"-\", \"*\", \"/\", \"<\", \">\", \"=\", \"<=\", \">=\", \"==\", \"!=\", \"++\", \"--\", \"%\"}\n",
    "\n",
    "delimiters = ['(', ')', '{', '}', '[', ']', '\"', \"'\", ';', '#', ',']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T17:17:37.005041300Z",
     "start_time": "2024-01-17T17:17:36.964121700Z"
    }
   },
   "id": "9a4d029e40b90dc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def detect_keywords(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in keywords:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_operators(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in operators:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_delimiters(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word in delimiters:\n",
    "            arr.append(word)\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_num(text):\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            a = int(word)\n",
    "            arr.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    return list(set(arr))\n",
    "\n",
    "\n",
    "def detect_identifiers(text):\n",
    "    k = detect_keywords(text)\n",
    "    o = detect_operators(text)\n",
    "    d = detect_delimiters(text)\n",
    "    n = detect_num(text)\n",
    "    not_ident = k + o + d + n\n",
    "    arr = []\n",
    "    for word in text:\n",
    "        if word not in not_ident:\n",
    "            arr.append(word)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def tokenizer(txt):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "\n",
    "    while i < (len(txt)):\n",
    "\n",
    "        # if txt[i] == '\"':\n",
    "        #     string = '\"'\n",
    "        #     i = i + 1\n",
    "        #     while txt[i] != '\"':\n",
    "        #         string += txt[i]\n",
    "        #         i += 1\n",
    "        #     string += '\"'\n",
    "        #     tokens.append(string)\n",
    "\n",
    "        if txt[i] in delimiters:\n",
    "            string = txt[i]\n",
    "            i = i + 1\n",
    "            while txt[i] not in delimiters:\n",
    "                string += txt[i]\n",
    "                i += 1\n",
    "            string += txt[i]\n",
    "            tokens.append(string)\n",
    "\n",
    "        i = i + 1\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T17:17:37.029161200Z",
     "start_time": "2024-01-17T17:17:36.975641200Z"
    }
   },
   "id": "f54119d0e356efea"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:  ['int', 'return']\n",
      "Operators:  ['+', '=']\n",
      "Delimiters:  ['}', '{']\n",
      "Identifiers:  ['main()', 'printf(\"It', 'is', 'a', 'header', 'file\");', 'main()', 'a', '10,', 'b', '20;', 'printf(\"sum', 'is:%d\",', 'a', 'b);', '0;']\n",
      "Numbers:  []\n"
     ]
    }
   ],
   "source": [
    "with open('example.c') as t:\n",
    "    text = t.read().split()\n",
    "\n",
    "print(\"Keywords: \", detect_keywords(text))\n",
    "print(\"Operators: \", detect_operators(text))\n",
    "print(\"Delimiters: \", detect_delimiters(text))\n",
    "print(\"Identifiers: \", detect_identifiers(text))\n",
    "print(\"Numbers: \", detect_num(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T17:17:37.029161200Z",
     "start_time": "2024-01-17T17:17:36.984016500Z"
    }
   },
   "id": "7b143cdfb570ff59"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATATYPE', 'int'], ['IDENTIFIER', 'result'], ['OPERATOR', '='], ['INTEGER', '100'], ['END_STATEMENT', ';']]\n"
     ]
    }
   ],
   "source": [
    "import re  # for performing regex expressions\n",
    "\n",
    "tokens = []  # for string tokens\n",
    "source_code = 'int result = 100;'.split()  # turning source code into list of words\n",
    "\n",
    "# Loop through each source code word\n",
    "for word in source_code:\n",
    "\n",
    "    # This will check if a token has datatype decleration\n",
    "    if word in ['str', 'int', 'bool']:\n",
    "        tokens.append(['DATATYPE', word])\n",
    "\n",
    "    # This will look for an identifier which would be just a word\n",
    "    elif re.match(\"[a-z]\", word) or re.match(\"[A-Z]\", word):\n",
    "        tokens.append(['IDENTIFIER', word])\n",
    "\n",
    "    # This will look for an operator\n",
    "    elif word in '*-/+%=':\n",
    "        tokens.append(['OPERATOR', word])\n",
    "\n",
    "    # This will look for integer items and cast them as a number\n",
    "    elif re.match(\".[0-9]\", word):\n",
    "        if word[len(word) - 1] == ';':\n",
    "            tokens.append([\"INTEGER\", word[:-1]])\n",
    "            tokens.append(['END_STATEMENT', ';'])\n",
    "        else:\n",
    "            tokens.append([\"INTEGER\", word])\n",
    "\n",
    "print(tokens)  # Outputs the token array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T17:17:37.030164200Z",
     "start_time": "2024-01-17T17:17:36.999671700Z"
    }
   },
   "id": "2523cab0abad54d1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T17:17:37.031154100Z",
     "start_time": "2024-01-17T17:17:37.006142400Z"
    }
   },
   "id": "4ae1f2bad49eba4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
